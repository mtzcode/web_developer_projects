name: Automated Testing - Mercado Fácil

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  FLUTTER_VERSION: '3.19.0'

jobs:
  # ===== UNIT TESTS =====
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Install dependencies
        run: flutter pub get

      - name: Run unit tests
        run: flutter test --coverage

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: coverage/lcov.info
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

      - name: Generate coverage report
        run: |
          genhtml coverage/lcov.info -o coverage/html
          echo "Coverage report generated in coverage/html/"

      - name: Upload coverage report
        uses: actions/upload-artifact@v3
        with:
          name: coverage-report-${{ github.run_number }}
          path: coverage/html/
          retention-days: 30

  # ===== WIDGET TESTS =====
  widget-tests:
    name: Widget Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Install dependencies
        run: flutter pub get

      - name: Run widget tests
        run: flutter test test/widget/

      - name: Upload widget test results
        uses: actions/upload-artifact@v3
        with:
          name: widget-test-results-${{ github.run_number }}
          path: test/widget/
          retention-days: 30

  # ===== INTEGRATION TESTS =====
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Install dependencies
        run: flutter pub get

      - name: Run integration tests
        run: flutter test test/integration/

      - name: Upload integration test results
        uses: actions/upload-artifact@v3
        with:
          name: integration-test-results-${{ github.run_number }}
          path: test/integration/
          retention-days: 30

  # ===== PERFORMANCE TESTS =====
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Install dependencies
        run: flutter pub get

      - name: Run performance tests
        run: |
          # Test build performance
          time flutter build apk --debug
          time flutter build web --debug
          
          # Test test execution performance
          time flutter test --coverage
          
          # Generate performance report
          echo "Performance Test Results:" > performance-report.txt
          echo "Build APK: $(time flutter build apk --debug 2>&1 | grep real)" >> performance-report.txt
          echo "Build Web: $(time flutter build web --debug 2>&1 | grep real)" >> performance-report.txt
          echo "Test Execution: $(time flutter test --coverage 2>&1 | grep real)" >> performance-report.txt

      - name: Upload performance report
        uses: actions/upload-artifact@v3
        with:
          name: performance-report-${{ github.run_number }}
          path: performance-report.txt
          retention-days: 30

  # ===== SECURITY TESTS =====
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Install dependencies
        run: flutter pub get

      - name: Run security analysis
        run: |
          # Check for known vulnerabilities in dependencies
          flutter pub deps --style=tree
          
          # Analyze code for security issues
          flutter analyze --no-fatal-infos
          
          # Check for hardcoded secrets
          grep -r "password\|secret\|key\|token" lib/ || echo "No hardcoded secrets found"

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  # ===== ACCESSIBILITY TESTS =====
  accessibility-tests:
    name: Accessibility Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Install dependencies
        run: flutter pub get

      - name: Run accessibility tests
        run: |
          # Test for accessibility issues in widgets
          flutter test test/accessibility/
          
          # Check for semantic labels
          grep -r "semanticLabel\|label" lib/ || echo "No semantic labels found"
          
          # Check for proper contrast ratios (placeholder)
          echo "Accessibility tests completed"

      - name: Upload accessibility test results
        uses: actions/upload-artifact@v3
        with:
          name: accessibility-test-results-${{ github.run_number }}
          path: test/accessibility/
          retention-days: 30

  # ===== TEST SUMMARY =====
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, widget-tests, integration-tests, performance-tests, security-tests, accessibility-tests]
    if: always()
    steps:
      - name: Generate test summary
        run: |
          echo "# Test Summary - ${{ github.run_number }}" > test-summary.md
          echo "## Test Results" >> test-summary.md
          echo "- Unit Tests: ${{ needs.unit-tests.result }}" >> test-summary.md
          echo "- Widget Tests: ${{ needs.widget-tests.result }}" >> test-summary.md
          echo "- Integration Tests: ${{ needs.integration-tests.result }}" >> test-summary.md
          echo "- Performance Tests: ${{ needs.performance-tests.result }}" >> test-summary.md
          echo "- Security Tests: ${{ needs.security-tests.result }}" >> test-summary.md
          echo "- Accessibility Tests: ${{ needs.accessibility-tests.result }}" >> test-summary.md
          echo "" >> test-summary.md
          echo "## Coverage" >> test-summary.md
          echo "Coverage report available in artifacts" >> test-summary.md
          echo "" >> test-summary.md
          echo "## Next Steps" >> test-summary.md
          if [ "${{ needs.unit-tests.result }}" == "success" ] && [ "${{ needs.widget-tests.result }}" == "success" ] && [ "${{ needs.integration-tests.result }}" == "success" ]; then
            echo "✅ All tests passed - Ready for deployment" >> test-summary.md
          else
            echo "❌ Some tests failed - Review required" >> test-summary.md
          fi

      - name: Upload test summary
        uses: actions/upload-artifact@v3
        with:
          name: test-summary-${{ github.run_number }}
          path: test-summary.md
          retention-days: 30

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('test-summary.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            }); 